---
layout: post
title:  An Adversarial Approach to Hard Triplet Generation
published: true
---

An overview of the paper “[An Adversarial Approach to Hard Triplet Generation](https://arxiv.org/pdf/1611.03530.pdf)”.
<!--break-->
The paper brings to notice that the major challenge lies in distinguishing similar images from different categories. All images and tables in this post are from their paper.

The current state-of-the-art is to mine the most hard triplet examples from the mini-batch to train the network. However, mining-based methods tend to look into these triplets that are hard in terms of the current estimated network, rather than deliberately generating those hard triplets that really matter in globally optimizing the network. For this purpose, the authors propose an adversarial network for Hard Triplet Generation (HTG) to optimize the network ability in distinguishing similar examples of different categories as well as grouping varied examples of the same categories.

## Hard Triplet Generation

We use triplet loss since, it is proved to perform better than contrastive loss. Here, <img src="https://latex.codecogs.com/svg.latex?d(x_1,x_2)" title="d(x_1,x_2)" /> is the squared Euclidean distance between two l2-normalized feature vectors.

### Adversarial Triplet Generator G

<img src="https://latex.codecogs.com/svg.latex?G" title="G" /> learns to produce challenging triplets of examples by pushing apart the vectors from the same category while pulling closer the vectors from different categories.The objective function of <img src="https://latex.codecogs.com/svg.latex?G" title="G" /> looks like: <img src="https://latex.codecogs.com/svg.latex?\min(d(a,n)-d(a,p)&plus;m,0)" title="\min(d(a,n)-d(a,p)+m,0)" />. Note, this isnt same as triplet loss, as the <img src="https://latex.codecogs.com/svg.latex?d(x,y)-d(x,z)" title="d(x,y)-d(x,z)" /> has been inverted here. The objective function to train <img src="https://latex.codecogs.com/svg.latex?F" title="F" /> looks like a simple triplet loss. <img src="https://latex.codecogs.com/svg.latex?F" title="F" /> is trained through hard triplets of examples generated by <img src="https://latex.codecogs.com/svg.latex?G" title="G" /> by pulling the positive pair closer and pushing the negative pair apart to meet the margin <img src="https://latex.codecogs.com/svg.latex?m" title="m" />.

### Multi-category Discriminator D

Without a discriminator, we might get random noisy triplets. The discriminator <img src="https://latex.codecogs.com/svg.latex?D" title="D" /> categories it into <img src="https://latex.codecogs.com/svg.latex?K&plus;1" title="K+1" /> categories, where the first <img src="https://latex.codecogs.com/svg.latex?K" title="K" /> categories are real classes and the last is a fake class. We try to minimize <img src="https://latex.codecogs.com/svg.latex?L_{\mathit{tri}}&space;=&space;L_{\mathit{real}}&plus;bL_{\mathit{fake}}" title="L = L_{\mathit{real}}+bL_{\mathit{fake}}" />. Here <img src="https://latex.codecogs.com/svg.latex?L_{\mathit{real}}" title="L_{\mathit{real}}" /> is average of softmax loss of <img src="https://latex.codecogs.com/svg.latex?a" title="a" />,<img src="https://latex.codecogs.com/svg.latex?a" title="a" /> and <img src="https://latex.codecogs.com/svg.latex?n" title="n" /> falling in the right labels. We do the same for <img src="https://latex.codecogs.com/svg.latex?L_{\mathit{fake}}" title="L_{\mathit{fake}}" />. To enforce label preservation assumption in <img src="https://latex.codecogs.com/svg.latex?G" title="G" />, we create a new loss <img src="https://latex.codecogs.com/svg.latex?L_{\mathit{cls}}" title="L_{\mathit{cls}}" /> which is similar to <img src="https://latex.codecogs.com/svg.latex?L_{\mathit{fake}}" title="L_{\mathit{fake}}" />, but assuming that the generator was successful in generating a triplet.
Hence, <img src="https://latex.codecogs.com/svg.latex?G" title="G" /> will now be minimizing <img src="https://latex.codecogs.com/svg.latex?L_{\mathit{tri}}&space;&plus;&space;bL_{\mathit{cls}}" title="L_{\mathit{tri}} + bL_{\mathit{cls}}" />.
